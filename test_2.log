/home/scratch/sywang/anaconda3/lib/python3.5/site-packages/sklearn/utils/fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead
  if 'order' in inspect.getargspec(np.copy)[0]:
INFO:tensorflow:Loading config from /home/scratch/sywang/seq2seq/example_configs/nmt_medium.yml
INFO:tensorflow:Loading config from /home/scratch/sywang/seq2seq/example_configs/train_seq2seq_optimized.yml
INFO:tensorflow:Loading config from /home/scratch/sywang/seq2seq/example_configs/text_metrics.yml
INFO:tensorflow:Final Config:
buckets: 10,20,30,40
default_params:
- {separator: ' '}
- {postproc_fn: seq2seq.data.postproc.strip_bpe}
hooks:
- {class: PrintModelAnalysisHook}
- {class: MetadataCaptureHook}
- {class: SyncReplicasOptimizerHook}
- class: TrainSampleHook
  params: {every_n_steps: 10000}
metrics:
- {class: LogPerplexityMetricSpec}
- class: BleuMetricSpec
  params: {postproc_fn: seq2seq.data.postproc.strip_bpe, separator: ' '}
model: AttentionSeq2Seq
model_params:
  attention.class: seq2seq.decoders.attention.AttentionLayerBahdanau
  attention.params: {num_units: 256}
  bridge.class: seq2seq.models.bridges.ZeroBridge
  decoder.class: seq2seq.decoders.AttentionDecoder
  decoder.params:
    rnn_cell:
      cell_class: GRUCell
      cell_params: {num_units: 256}
      dropout_input_keep_prob: 0.8
      dropout_output_keep_prob: 1.0
      num_layers: 2
  embedding.dim: 256
  encoder.class: seq2seq.encoders.BidirectionalRNNEncoder
  encoder.params:
    rnn_cell:
      cell_class: GRUCell
      cell_params: {num_units: 256}
      dropout_input_keep_prob: 0.8
      dropout_output_keep_prob: 1.0
      num_layers: 1
  optimizer.learning_rate: 0.0001
  optimizer.name: Adam
  optimizer.params: {epsilon: 8.0e-07}
  source.max_seq_len: 50
  source.reverse: false
  target.max_seq_len: 50

WARNING:tensorflow:Ignoring config flag: default_params
WARNING:tensorflow:From /home/scratch/sywang/seq2seq/bin/train.py:272: run (from tensorflow.contrib.learn.python.learn.learn_runner) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.estimator.train_and_evaluate.
WARNING:tensorflow:From /home/scratch/sywang/seq2seq/bin/train.py:135: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.
Instructions for updating:
When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.
INFO:tensorflow:Creating ParallelTextInputPipeline in mode=train
INFO:tensorflow:
ParallelTextInputPipeline:
  num_epochs: null
  shuffle: true
  source_delimiter: ' '
  source_files: [/home/scratch/sywang/project/dataset/google/50//train/buggy.txt]
  target_delimiter: ' '
  target_files: [/home/scratch/sywang/project/dataset/google/50//train/fixed.txt]

INFO:tensorflow:Creating ParallelTextInputPipeline in mode=eval
INFO:tensorflow:
ParallelTextInputPipeline:
  num_epochs: 1
  shuffle: false
  source_delimiter: ' '
  source_files: [/home/scratch/sywang/project/dataset/google/50//eval/buggy.txt]
  target_delimiter: ' '
  target_files: [/home/scratch/sywang/project/dataset/google/50//eval/fixed.txt]

WARNING:tensorflow:From /home/scratch/sywang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1179: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.
Instructions for updating:
Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*
INFO:tensorflow:Using config: {'_is_chief': True, '_task_type': None, '_device_fn': None, '_keep_checkpoint_max': 2, '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 4, '_model_dir': '/home/scratch/sywang/project/dataset/google/50/', '_session_config': None, '_log_step_count_steps': 100, '_num_worker_replicas': 0, '_environment': 'local', '_save_checkpoints_secs': None, '_save_summary_steps': 100, '_master': '', '_train_distribute': None, '_task_id': 0, '_save_checkpoints_steps': 10000, '_num_ps_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f04d11957b8>, '_tf_random_seed': None}
INFO:tensorflow:Creating PrintModelAnalysisHook in mode=train
INFO:tensorflow:
PrintModelAnalysisHook: {}

INFO:tensorflow:Creating MetadataCaptureHook in mode=train
INFO:tensorflow:
MetadataCaptureHook: {step: 10}

INFO:tensorflow:Creating SyncReplicasOptimizerHook in mode=train
INFO:tensorflow:
SyncReplicasOptimizerHook: {}

INFO:tensorflow:Creating TrainSampleHook in mode=train
INFO:tensorflow:
TrainSampleHook: {every_n_secs: null, every_n_steps: 10000, source_delimiter: ' ',
  target_delimiter: ' '}

INFO:tensorflow:Creating LogPerplexityMetricSpec in mode=eval
INFO:tensorflow:
LogPerplexityMetricSpec: {}

INFO:tensorflow:Creating BleuMetricSpec in mode=eval
INFO:tensorflow:
BleuMetricSpec: {eos_token: SEQUENCE_END, postproc_fn: seq2seq.data.postproc.strip_bpe,
  separator: ' ', sos_token: SEQUENCE_START}

WARNING:tensorflow:From /home/scratch/sywang/seq2seq/seq2seq/contrib/experiment.py:26: Experiment.__init__ (from tensorflow.contrib.learn.python.learn.experiment) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.estimator.train_and_evaluate. You will also have to convert to a tf.estimator.Estimator.
INFO:tensorflow:Training model for 1000 steps
INFO:tensorflow:Creating AttentionSeq2Seq in mode=train
INFO:tensorflow:
AttentionSeq2Seq:
  attention.class: seq2seq.decoders.attention.AttentionLayerBahdanau
  attention.params: {num_units: 256}
  bridge.class: seq2seq.models.bridges.ZeroBridge
  bridge.params: {}
  decoder.class: seq2seq.decoders.AttentionDecoder
  decoder.params:
    rnn_cell:
      cell_class: GRUCell
      cell_params: {num_units: 256}
      dropout_input_keep_prob: 0.8
      dropout_output_keep_prob: 1.0
      num_layers: 2
  embedding.dim: 256
  embedding.init_scale: 0.04
  embedding.share: false
  encoder.class: seq2seq.encoders.BidirectionalRNNEncoder
  encoder.params:
    rnn_cell:
      cell_class: GRUCell
      cell_params: {num_units: 256}
      dropout_input_keep_prob: 0.8
      dropout_output_keep_prob: 1.0
      num_layers: 1
  inference.beam_search.beam_width: 0
  inference.beam_search.choose_successors_fn: choose_top_k
  inference.beam_search.length_penalty_weight: 0.0
  optimizer.clip_embed_gradients: 0.1
  optimizer.clip_gradients: 5.0
  optimizer.learning_rate: 0.0001
  optimizer.lr_decay_rate: 0.99
  optimizer.lr_decay_steps: 100
  optimizer.lr_decay_type: ''
  optimizer.lr_min_learning_rate: 1.0e-12
  optimizer.lr_staircase: false
  optimizer.lr_start_decay_at: 0
  optimizer.lr_stop_decay_at: 2147483647
  optimizer.name: Adam
  optimizer.params: {epsilon: 8.0e-07}
  optimizer.sync_replicas: 0
  optimizer.sync_replicas_to_aggregate: 0
  source.max_seq_len: 50
  source.reverse: false
  target.max_seq_len: 50
  vocab_source: /home/scratch/sywang/project/dataset/google/50//train/vocab.buggy.txt
  vocab_target: /home/scratch/sywang/project/dataset/google/50//train/vocab.fixed.txt

INFO:tensorflow:Creating vocabulary lookup table of size 338
INFO:tensorflow:Creating vocabulary lookup table of size 334
INFO:tensorflow:Creating BidirectionalRNNEncoder in mode=train
INFO:tensorflow:
BidirectionalRNNEncoder:
  init_scale: 0.04
  rnn_cell:
    cell_class: GRUCell
    cell_params: {num_units: 256}
    dropout_input_keep_prob: 0.8
    dropout_output_keep_prob: 1.0
    num_layers: 1
    residual_combiner: add
    residual_connections: false
    residual_dense: false

WARNING:tensorflow:From /home/scratch/sywang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.
Instructions for updating:
seq_dim is deprecated, use seq_axis instead
WARNING:tensorflow:From /home/scratch/sywang/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.
Instructions for updating:
batch_dim is deprecated, use batch_axis instead
INFO:tensorflow:Creating AttentionLayerBahdanau in mode=train
INFO:tensorflow:
AttentionLayerBahdanau: {num_units: 256}

INFO:tensorflow:Creating AttentionDecoder in mode=train
INFO:tensorflow:
AttentionDecoder:
  init_scale: 0.04
  max_decode_length: 100
  rnn_cell:
    cell_class: GRUCell
    cell_params: {num_units: 256}
    dropout_input_keep_prob: 0.8
    dropout_output_keep_prob: 1.0
    num_layers: 2
    residual_combiner: add
    residual_connections: false
    residual_dense: false

INFO:tensorflow:Creating ZeroBridge in mode=train
INFO:tensorflow:
ZeroBridge: {}

WARNING:tensorflow:From /home/scratch/sywang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/function.py:986: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.
Instructions for updating:
Shapes are always computed; don't use the compute_shapes as it has no effect.
WARNING:tensorflow:From /home/scratch/sywang/seq2seq/seq2seq/models/model_base.py:108: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.get_global_step
WARNING:tensorflow:From /home/scratch/sywang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1240: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.
Instructions for updating:
When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.
INFO:tensorflow:Create CheckpointSaverHook.
WARNING:tensorflow:Issue encountered when serializing trainable_variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'tokens_counter' has type str, but expected one of: int, long, bool
WARNING:tensorflow:Issue encountered when serializing variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'tokens_counter' has type str, but expected one of: int, long, bool
WARNING:tensorflow:From /home/scratch/sywang/seq2seq/seq2seq/training/hooks.py:249: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.
Instructions for updating:
Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details
-dump_to_file option is deprecated. Please use -output file:outfile=<filename>
-output stdout is overwritten with -output file:outfile=/home/scratch/sywang/project/dataset/google/50/model_analysis.txt
64 ops no flops stats due to incomplete shapes.
INFO:tensorflow:
Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
param: Number of parameters (in the Variable).

Profile:
node name | # parameters
_TFProfRoot (--/2.62m params)
  model (--/2.62m params)
    model/att_seq2seq (--/2.62m params)
      model/att_seq2seq/Variable (1, 1/1 params)
      model/att_seq2seq/decode (--/1.75m params)
        model/att_seq2seq/decode/attention (--/197.38k params)
          model/att_seq2seq/decode/attention/att_keys (--/131.33k params)
            model/att_seq2seq/decode/attention/att_keys/biases (256, 256/256 params)
            model/att_seq2seq/decode/attention/att_keys/weights (512x256, 131.07k/131.07k params)
          model/att_seq2seq/decode/attention/att_query (--/65.79k params)
            model/att_seq2seq/decode/attention/att_query/biases (256, 256/256 params)
            model/att_seq2seq/decode/attention/att_query/weights (256x256, 65.54k/65.54k params)
          model/att_seq2seq/decode/attention/v_att (256, 256/256 params)
        model/att_seq2seq/decode/attention_decoder (--/1.46m params)
          model/att_seq2seq/decode/attention_decoder/decoder (--/1.46m params)
            model/att_seq2seq/decode/attention_decoder/decoder/attention_mix (--/196.86k params)
              model/att_seq2seq/decode/attention_decoder/decoder/attention_mix/biases (256, 256/256 params)
              model/att_seq2seq/decode/attention_decoder/decoder/attention_mix/weights (768x256, 196.61k/196.61k params)
            model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell (--/1.18m params)
              model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_0 (--/787.20k params)
                model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_0/gru_cell (--/787.20k params)
                  model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_0/gru_cell/candidate (--/262.40k params)
                    model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_0/gru_cell/candidate/bias (256, 256/256 params)
                    model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_0/gru_cell/candidate/kernel (1024x256, 262.14k/262.14k params)
                  model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_0/gru_cell/gates (--/524.80k params)
                    model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_0/gru_cell/gates/bias (512, 512/512 params)
                    model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_0/gru_cell/gates/kernel (1024x512, 524.29k/524.29k params)
              model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_1 (--/393.98k params)
                model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_1/gru_cell (--/393.98k params)
                  model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_1/gru_cell/candidate (--/131.33k params)
                    model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_1/gru_cell/candidate/bias (256, 256/256 params)
                    model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_1/gru_cell/candidate/kernel (512x256, 131.07k/131.07k params)
                  model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_1/gru_cell/gates (--/262.66k params)
                    model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_1/gru_cell/gates/bias (512, 512/512 params)
                    model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_1/gru_cell/gates/kernel (512x512, 262.14k/262.14k params)
            model/att_seq2seq/decode/attention_decoder/decoder/logits (--/85.84k params)
              model/att_seq2seq/decode/attention_decoder/decoder/logits/biases (334, 334/334 params)
              model/att_seq2seq/decode/attention_decoder/decoder/logits/weights (256x334, 85.50k/85.50k params)
        model/att_seq2seq/decode/target_embedding (--/85.50k params)
          model/att_seq2seq/decode/target_embedding/W (334x256, 85.50k/85.50k params)
      model/att_seq2seq/encode (--/874.50k params)
        model/att_seq2seq/encode/bidi_rnn_encoder (--/787.97k params)
          model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn (--/787.97k params)
            model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/bw (--/393.98k params)
              model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/bw/gru_cell (--/393.98k params)
                model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/bw/gru_cell/candidate (--/131.33k params)
                  model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/bw/gru_cell/candidate/bias (256, 256/256 params)
                  model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/bw/gru_cell/candidate/kernel (512x256, 131.07k/131.07k params)
                model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/bw/gru_cell/gates (--/262.66k params)
                  model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/bw/gru_cell/gates/bias (512, 512/512 params)
                  model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/bw/gru_cell/gates/kernel (512x512, 262.14k/262.14k params)
            model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/fw (--/393.98k params)
              model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/fw/gru_cell (--/393.98k params)
                model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/fw/gru_cell/candidate (--/131.33k params)
                  model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/fw/gru_cell/candidate/bias (256, 256/256 params)
                  model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/fw/gru_cell/candidate/kernel (512x256, 131.07k/131.07k params)
                model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/fw/gru_cell/gates (--/262.66k params)
                  model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/fw/gru_cell/gates/bias (512, 512/512 params)
                  model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/fw/gru_cell/gates/kernel (512x512, 262.14k/262.14k params)
        model/att_seq2seq/encode/source_embedding (--/86.53k params)
          model/att_seq2seq/encode/source_embedding/W (338x256, 86.53k/86.53k params)

INFO:tensorflow:Graph was finalized.
2018-09-26 14:37:56.749115: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
INFO:tensorflow:Restoring parameters from /home/scratch/sywang/project/dataset/google/50/model.ckpt-10000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
WARNING:tensorflow:Issue encountered when serializing trainable_variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'tokens_counter' has type str, but expected one of: int, long, bool
WARNING:tensorflow:Issue encountered when serializing variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'tokens_counter' has type str, but expected one of: int, long, bool
INFO:tensorflow:Saving checkpoints for 10000 into /home/scratch/sywang/project/dataset/google/50/model.ckpt.
WARNING:tensorflow:Issue encountered when serializing trainable_variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'tokens_counter' has type str, but expected one of: int, long, bool
WARNING:tensorflow:Issue encountered when serializing variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'tokens_counter' has type str, but expected one of: int, long, bool
INFO:tensorflow:Prediction followed by Target @ Step 10001
====================================================================================================
protected void METHOD_1 ( ) { bind ( ) . to ( VAR_2 class ) ; bind ( ) . to ( VAR_2 class ) ; } ( ) . to ( VAR_3 class ) ; } SEQUENCE_END
protected void METHOD_1 ( ) { METHOD_2 ( ) . to ( VAR_2 class ) ; METHOD_2 ( ) . to ( VAR_3 class ) ; METHOD_2 ( ) . to ( VAR_4 class ) ; } SEQUENCE_END

private void METHOD_1 ( final TYPE_1 . PatchSetApproval VAR_1 ) { if ( VAR_1 . null ) { VAR_1 . METHOD_2 ( VAR_1 . get ( VAR_1 ) get ( ) ) ) get ( ) ) ; } } SEQUENCE_END
private void METHOD_1 ( final com.google.gerrit.reviewdb.client . PatchSetApproval VAR_1 ) { if ( VAR_1 != null ) { VAR_2 . METHOD_1 ( VAR_3 . create ( VAR_1 . getAccountId ( ) ) . METHOD_2 ( ) ) ; } } SEQUENCE_END

public static void METHOD_1 ( final TYPE_1 . PatchSetApproval VAR_1 , final TYPE_2 . Id VAR_1 ) { return new . METHOD_2 ( VAR_1 . VAR_2 . METHOD_2 ( ) , get ( ) ) ) ; } SEQUENCE_END
public static boolean METHOD_1 ( final TYPE_1 . Id VAR_1 , final TYPE_2 . NameKey VAR_2 ) { return TYPE_5 . METHOD_1 ( VAR_1 , TYPE_4 . METHOD_2 ( ) . get ( VAR_2 ) ) ; } SEQUENCE_END

public TYPE_1 METHOD_1 ( TYPE_2 VAR_1 ) throws TYPE_2 { try { return VAR_1 . create ( db . db ) ; METHOD_3 ( ) ; } catch ( com.google.gwtorm.server.OrmException e com.google.gwtorm.server.OrmException e java.io.IOException e ) { throw new TYPE_3 ( STRING_1 , e ) ; } } SEQUENCE_END
public TYPE_1 METHOD_1 ( TYPE_2 input ) throws TYPE_3 { try { return VAR_1 . apply ( change , input ) . value ( ) ; } catch ( TYPE_4 | java.io.IOException | com.google.gwtorm.server.OrmException e ) { throw new TYPE_3 ( STRING_1 , e ) ; } } SEQUENCE_END

public boolean METHOD_1 ( com.google.gerrit.reviewdb.client.Change cd ) throws com.google.gwtorm.server.OrmException { return change = cd . change ( ) . return ( change . null ) && ( ( change . METHOD_2 ( ) . METHOD_3 ( ) ( ) ) ) ) STRING_2 ) ; } SEQUENCE_END
public boolean METHOD_1 ( com.google.gerrit.server.query.change.ChangeData cd ) throws com.google.gwtorm.server.OrmException { com.google.gerrit.reviewdb.client.Change change = cd . change ( ) ; return ( change != null ) && ( ( change . METHOD_2 ( ) . METHOD_3 ( getValue ( ) ) ) > 0 ) ; } SEQUENCE_END

private void METHOD_1 ( java.lang.String VAR_1 , TYPE_1 VAR_2 , ) { if ( ( . METHOD_2 ( ) ) { VAR_1 . METHOD_3 ( ( ( STRING_1 + + ( ) ) VAR_2 ) ; } } SEQUENCE_END
private void METHOD_1 ( java.lang.String msg , TYPE_1 ... args ) { if ( VAR_1 . METHOD_2 ( ) ) { VAR_1 . METHOD_3 ( ( ( VAR_2 ) + msg ) , args ) ; } } SEQUENCE_END

public void METHOD_1 ( ) throws java.lang.Exception { com.google.common.truth.Truth.assertThat = STRING_1 ) STRING_1 ) ; com.google.common.truth.Truth.assertThat . STRING_1 ) STRING_2 ) ; com.google.common.truth.Truth.assertThat ( STRING_2 ) . com.google.common.truth.Truth.assertThat ( STRING_2 ) . METHOD_3 ( METHOD_3 ( ) ) ) isEqualTo ) ; isEqualTo ( STRING_2 ) ; } SEQUENCE_END
public void METHOD_1 ( ) throws java.lang.Exception { group ( STRING_1 , STRING_2 ) ; group ( STRING_3 , STRING_2 ) ; METHOD_2 ( STRING_4 ) ; METHOD_2 ( STRING_5 ) ; com.google.common.truth.Truth.assertThat ( METHOD_3 ( STRING_4 ) . name ) . isEqualTo ( STRING_1 ) ; } SEQUENCE_END

public void METHOD_1 ( ) throws java.lang.Exception { TYPE_1 VAR_1 = new ( ) ; org.junit.Assert.assertEquals ( VAR_1 , METHOD_2 , VAR_2 , VAR_3 ) ; assertThat ( VAR_3 ) . isEqualTo ( ) ; } SEQUENCE_END
public void METHOD_1 ( ) throws java.lang.Exception { TYPE_1 VAR_1 = METHOD_2 ( ) ; METHOD_3 ( VAR_1 . changeId , VAR_4 , VAR_5 ) ; assertThat ( VAR_6 ) . METHOD_4 ( ) ; } SEQUENCE_END

private void METHOD_1 ( ) throws try ( TYPE_1 TYPE_1 VAR_1 ) VAR_1 ( ) ) { VAR_1 . METHOD_3 ( ) ) ; VAR_1 . METHOD_3 ( ) ) ; } SEQUENCE_END . METHOD_4 ( ) ; } SEQUENCE_END
private void METHOD_1 ( ) { for ( final java.lang.String name : METHOD_2 ( ) ) { p . METHOD_3 ( name ) ; p . METHOD_3 ( CHAR_1 ) ; } p . METHOD_4 ( ) ; } SEQUENCE_END

public void METHOD_1 ( ) throws java.lang.Exception { VAR_1 ( ) ) . VAR_1 . METHOD_3 ( ( . ) ; VAR_1 . METHOD_4 ( ) . METHOD_4 ( STRING_1 . get ( ) ) . METHOD_4 ( ) ) ; METHOD_5 ( ) ; } SEQUENCE_END
public void METHOD_1 ( ) throws java.lang.Exception { METHOD_2 ( STRING_1 ) ; VAR_1 . METHOD_3 ( VAR_2 class ) ; VAR_3 . projects ( ) . name ( project . get ( ) ) . METHOD_4 ( STRING_2 ) . get ( ) ; } SEQUENCE_END

public java.lang.String METHOD_1 ( ) { return VAR_1 . METHOD_2 ; METHOD_2 ( ) ; if ( != null ? null : VAR_2 : } SEQUENCE_END
public java.lang.String METHOD_1 ( ) { java.lang.String s = VAR_1 . METHOD_1 ( ) ; return s == null ? STRING_1 : s ; } SEQUENCE_END

public void METHOD_1 ( ) throws java.lang.Exception { TYPE_1 VAR_1 = new TYPE_1 ( ) ; VAR_1 . METHOD_2 = in ; STRING_1 ) ; VAR_1 . METHOD_3 ( ) . get ( STRING_1 ) ; get ( ) ) ; } SEQUENCE_END
public void METHOD_1 ( ) throws java.lang.Exception { TYPE_1 in = new TYPE_1 ( ) ; in . name = name ( STRING_1 ) ; VAR_1 . projects ( ) . name ( STRING_2 ) . create ( in ) ; } SEQUENCE_END

private TYPE_1 METHOD_1 ( final java.lang.String VAR_1 ) { return new TYPE_1 ( VAR_2 , VAR_3 , VAR_4 , null , VAR_4 , VAR_4 , METHOD_2 < java.lang.String > METHOD_2 ( ) , null , null , null ) null ) ; } SEQUENCE_END
static TYPE_1 METHOD_1 ( final java.lang.String VAR_1 ) { return new TYPE_1 ( VAR_2 , VAR_3 , null , VAR_1 , VAR_4 , VAR_5 . Collections < TYPE_2 > METHOD_2 ( ) , 0 , 0 , 0 , 0 ) ; } SEQUENCE_END

public void METHOD_1 ( ) { if ( VAR_1 . METHOD_2 ( ) ) ) ) ; install ( new TYPE_1 ( ) ) ; } ( VAR_3 TYPE_1 ( ) ) ; } SEQUENCE_END
public void METHOD_1 ( ) { install ( VAR_1 . METHOD_2 ( VAR_2 class ) ) ; install ( new TYPE_1 ( ) ) ; install ( new TYPE_2 ( ) ) ; } SEQUENCE_END

public void METHOD_1 ( ) throws java.lang.Exception { try = new . METHOD_2 ( ) ) VAR_1 ) ; com.google.common.truth.Truth.assertThat . METHOD_3 ( VAR_1 ; com.google.common.truth.Truth.assertThat . new . METHOD_3 ( ) ) ; } SEQUENCE_END
public void METHOD_1 ( ) throws java.io.IOException { VAR_1 = TYPE_1 . METHOD_2 ( STRING_1 , STRING_2 ) ; VAR_1 . delete ( ) ; repo = TYPE_2 . METHOD_3 ( VAR_1 ) ; } SEQUENCE_END

public void METHOD_1 ( TYPE_1 VAR_1 , TYPE_2 VAR_2 ) { TYPE_2 . = new TYPE_1 ( ) . VAR_2 ) ; VAR_2 ( VAR_1 VAR_1 ) != null ) { VAR_2 = new . } = METHOD_3 ( VAR_2 ; } } { VAR_1 = new ; }
public void METHOD_1 ( TYPE_1 req , TYPE_2 VAR_1 ) { TYPE_3 VAR_2 = new TYPE_3 ( req , VAR_1 ) ; if ( ( query ) == null ) { query = VAR_2 ; VAR_2 . METHOD_2 ( ) ; } else { query = VAR_2 ; }

private java.lang.String METHOD_1 ( TYPE_1 VAR_1 , TYPE_2 VAR_2 ) throws java.lang.Exception { return r = new . create ( VAR_2 , repo , VAR_3 , VAR_2 , VAR_2 java.lang.String ( ) ) ) ; return r . METHOD_2 ( ) , VAR_1 ) ; isEqualTo ( ) ;
private java.lang.String METHOD_1 ( TYPE_1 git , TYPE_2 VAR_1 ) throws java.lang.Exception { TYPE_3 VAR_2 = VAR_3 . create ( db , VAR_1 , VAR_4 , VAR_5 , new java.lang.String ( VAR_6 ) ) ; return VAR_2 . METHOD_2 ( git , STRING_1 ) . getChangeId ( ) ;

public void METHOD_1 ( final TYPE_1 VAR_1 , final TYPE_2 VAR_2 ) { VAR_1 . METHOD_2 ( VAR_1 ) ; VAR_1 . METHOD_3 ( VAR_1 ) get ) ) ) . } . METHOD_3 ( VAR_1 ) ; } SEQUENCE_END
public void METHOD_1 ( final java.lang.StringBuilder VAR_1 , final TYPE_2 VAR_2 ) { VAR_1 . append ( CHAR_1 ) ; VAR_1 . append ( VAR_2 . name ( ) ) ; VAR_1 . append ( CHAR_1 ) ; } SEQUENCE_END

public METHOD_1 ( final . Id id ) { SEQUENCE_END
void METHOD_1 ( TYPE_1 . NameKey branch ) ; SEQUENCE_END

public boolean METHOD_1 ( com.google.gerrit.reviewdb.server.ReviewDb change , int db ) throws com.google.gwtorm.server.OrmException { if ( ( VAR_1 . METHOD_2 ( ) ) { ( ( ( METHOD_2 ( ) ) null ) ) ) ) { return null ; } return METHOD_3 ( ) ) ; } SEQUENCE_END
public boolean METHOD_1 ( com.google.gerrit.reviewdb.client.PatchSet ps , com.google.gerrit.reviewdb.server.ReviewDb db ) throws com.google.gwtorm.server.OrmException { if ( ( ps . METHOD_2 ( ) ) && ( ! ( METHOD_3 ( db , null ) ) ) ) { return false ; } return METHOD_4 ( db ) ; } SEQUENCE_END

public void onSuccess ( ) { TYPE_1 . display ( TYPE_2 , new TYPE_2 ( new , id , getParentKey ( ) , new , getParentKey ( ) , new . id , ) ; } SEQUENCE_END
public void onSuccess ( ) { TYPE_1 . display ( token , new TYPE_3 ( VAR_1 , id . getParentKey ( ) , id . get ( ) , VAR_2 , line ) ) ; } SEQUENCE_END

public void METHOD_1 ( java.lang.String VAR_1 , TYPE_1 VAR_2 ) throws java.lang.Exception { try { VAR_1 . METHOD_2 ( VAR_2 , VAR_1 , VAR_2 ) ; } catch ( TYPE_1 e ) { throw new . METHOD_2 ( VAR_1 , e ) ; } } SEQUENCE_END
public void METHOD_1 ( java.lang.String VAR_1 , TYPE_1 VAR_2 ) throws TYPE_2 { try { VAR_3 . apply ( VAR_4 , VAR_1 , VAR_2 ) ; } catch ( java.lang.Exception e ) { throw TYPE_3 . METHOD_3 ( STRING_1 , e ) ; } } SEQUENCE_END

public void METHOD_1 ( ) throws java.lang.Exception { java.lang.String VAR_1 = METHOD_2 ( STRING_1 . METHOD_3 ( ) ; com.google.common.truth.Truth.assertThat ( STRING_1 ) . com.google.common.truth.Truth.assertThat . METHOD_3 ( STRING_1 ( STRING_1 + STRING_2 ) ) STRING_2 ) ) ; isEqualTo ( ) ; } SEQUENCE_END
public void METHOD_1 ( ) throws java.lang.Exception { java.lang.String changeId = METHOD_2 ( ) . getChangeId ( ) ; METHOD_3 ( STRING_1 ) ; VAR_1 . METHOD_4 ( ( ( STRING_2 + changeId ) + STRING_3 ) ) . METHOD_5 ( ) ; } SEQUENCE_END

private TYPE_1 METHOD_1 ( ) { return TYPE_1 < TYPE_2 > VAR_1 = new TYPE_1 < TYPE_2 > ( ) ; final ( new TYPE_3 ( VAR_1 TYPE_2 ( ) ) ) ) ; return new . get ( ) ) ; } SEQUENCE_END
private TYPE_1 METHOD_1 ( ) { final java.util.List < TYPE_2 > modules = new java.util.ArrayList < TYPE_2 > ( ) ; modules.add ( new TYPE_3 ( new TYPE_4 ( VAR_1 ) ) ) ; return VAR_1 . METHOD_2 ( modules ) ; } SEQUENCE_END

protected void METHOD_1 ( TYPE_1 VAR_1 HttpServletResponse < , java.lang.String VAR_1 , java.lang.String VAR_2 , { METHOD_2 . METHOD_2 ( VAR_2 , ; METHOD_3 . METHOD_3 ( VAR_1 , VAR_2 ( ) ( ) , ; METHOD_3 ( VAR_1 ) ; } SEQUENCE_END
protected void METHOD_1 ( TYPE_2 . HttpServletResponse res , java.lang.String VAR_1 , java.lang.String VAR_2 ) { res . METHOD_2 ( VAR_2 ) ; res . METHOD_3 ( VAR_3 , ( STRING_1 + VAR_1 ) ) ; METHOD_4 ( res ) ; } SEQUENCE_END

private void METHOD_1 ( java.lang.String VAR_1 , { if ( ( . METHOD_2 ( ) ) { VAR_1 . METHOD_3 ( ( ( VAR_2 . + ( ) + ; } } SEQUENCE_END
private void METHOD_1 ( java.lang.String msg ) { if ( VAR_1 . METHOD_2 ( ) ) { VAR_1 . METHOD_3 ( ( ( VAR_2 ) + msg ) ) ; } } SEQUENCE_END

public void METHOD_1 ( ) throws TYPE_1 { try VAR_1 = METHOD_2 VAR_2 . METHOD_2 ( ) ) ) ) ; STRING_2 ; METHOD_3 ( ) ) ) ) ) VAR_1 ) ; } . METHOD_4 ( ) ; } ( ) ; } SEQUENCE_END
public void METHOD_1 ( ) throws TYPE_1 { boolean VAR_1 = ( VAR_2 . METHOD_2 ( VAR_3 class ) ) == null ; METHOD_3 ( config ( VAR_2 ) , VAR_1 ) ; base . METHOD_1 ( ) ; METHOD_4 ( ) ; } SEQUENCE_END

public void METHOD_1 ( ) throws TYPE_1 { try { VAR_1 . apply ( change , new TYPE_2 ( ) ) ; } catch ( com.google.gwtorm.server.OrmException e java.io.IOException e ) { throw new TYPE_2 ( STRING_1 , e ) ; } } SEQUENCE_END
public void index ( ) throws TYPE_1 { try { index . apply ( change , new TYPE_2 ( ) ) ; } catch ( java.io.IOException | com.google.gwtorm.server.OrmException e ) { throw new TYPE_1 ( STRING_1 , e ) ; } } SEQUENCE_END

public void METHOD_1 ( ) throws java.lang.Exception { TYPE_1 . Result > = METHOD_2 ( ) ; org.junit.Assert.assertEquals < TYPE_1 = TYPE_2 > ( = METHOD_2 ( ) , STRING_1 ) ; com.google.common.truth.Truth.assertThat ( VAR_1 . . isEqualTo ( ) ) ; } SEQUENCE_END
public void METHOD_1 ( ) throws java.lang.Exception { TYPE_1 . Result c = METHOD_2 ( ) ; java.util.Map < java.lang.String , TYPE_2 > VAR_1 = METHOD_3 ( c , null ) ; com.google.common.truth.Truth.assertThat ( VAR_1 ) . METHOD_4 ( 0 ) ; } SEQUENCE_END

public void onSuccess ( TYPE_1 result ) { if ( ( . METHOD_1 ( ) ) { TYPE_2 . display ( TYPE_3 . METHOD_2 ( project ) ) ; } } SEQUENCE_END
public void onSuccess ( TYPE_1 result ) { if ( VAR_1 . METHOD_1 ( ) ) { TYPE_2 . display ( TYPE_3 . METHOD_2 ( psId ) ) ; } } SEQUENCE_END

public TYPE_1 TYPE_1 . ( ) { if . METHOD_2 ( ) ( VAR_1 ) ) null ) ) null ) ; VAR_1 ( VAR_1 VAR_1 ) == null ) { VAR_1 = new TYPE_1 ( ) , ; } return VAR_1 ; } SEQUENCE_END
public synchronized TYPE_1 METHOD_1 ( ) { TYPE_2 . METHOD_2 ( ( ( VAR_1 ) == null ) , STRING_1 ) ; if ( ( VAR_2 ) == null ) { VAR_2 = new TYPE_1 ( VAR_3 ) ; } return VAR_2 ; } SEQUENCE_END

public static TYPE_1 METHOD_1 ( java.lang.String VAR_1 ) { return TYPE_1 TYPE_1 ( VAR_1 . METHOD_2 ( ) , METHOD_3 . ; } SEQUENCE_END
public final TYPE_1 METHOD_1 ( java.lang.String VAR_1 ) { return new TYPE_1 ( VAR_2 . METHOD_2 ( ) , VAR_1 ) ; } SEQUENCE_END

====================================================================================================


INFO:tensorflow:loss = 0.96389186, step = 10001
INFO:tensorflow:Performing full trace on next step.
INFO:tensorflow:Captured full trace at step 10002
INFO:tensorflow:Saved run_metadata to /home/scratch/sywang/project/dataset/google/50/run_meta
INFO:tensorflow:Saved timeline to /home/scratch/sywang/project/dataset/google/50/timeline.json
WARNING:tensorflow:From /home/scratch/sywang/seq2seq/seq2seq/training/hooks.py:133: write_op_log (from tensorflow.contrib.tfprof.tfprof_logger) is deprecated and will be removed after 2018-01-01.
Instructions for updating:
Use `tf.profiler.write_op_log. go/tfprof`
INFO:tensorflow:Saved op log to /home/scratch/sywang/project/dataset/google/50
INFO:tensorflow:global_step/sec: 1.50739
INFO:tensorflow:loss = 0.67344123, step = 10101 (66.337 sec)
INFO:tensorflow:global_step/sec: 1.97736
INFO:tensorflow:loss = 1.0746717, step = 10201 (50.574 sec)
INFO:tensorflow:global_step/sec: 2.06674
INFO:tensorflow:loss = 0.4819617, step = 10301 (48.386 sec)
INFO:tensorflow:global_step/sec: 2.04154
INFO:tensorflow:loss = 0.7063797, step = 10401 (48.982 sec)
INFO:tensorflow:global_step/sec: 2.06853
INFO:tensorflow:loss = 1.0513414, step = 10501 (48.343 sec)
INFO:tensorflow:global_step/sec: 2.09251
INFO:tensorflow:loss = 0.7199983, step = 10601 (47.791 sec)
INFO:tensorflow:global_step/sec: 2.05598
INFO:tensorflow:loss = 1.0103954, step = 10701 (48.638 sec)
INFO:tensorflow:global_step/sec: 2.10036
INFO:tensorflow:loss = 0.9981954, step = 10801 (47.611 sec)
INFO:tensorflow:global_step/sec: 2.09429
INFO:tensorflow:loss = 0.98565716, step = 10901 (47.749 sec)
INFO:tensorflow:Saving checkpoints for 11000 into /home/scratch/sywang/project/dataset/google/50/model.ckpt.
WARNING:tensorflow:Issue encountered when serializing trainable_variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'tokens_counter' has type str, but expected one of: int, long, bool
WARNING:tensorflow:Issue encountered when serializing variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'tokens_counter' has type str, but expected one of: int, long, bool
INFO:tensorflow:Loss for final step: 1.0474294.
INFO:tensorflow:Evaluating model now.
INFO:tensorflow:Creating AttentionSeq2Seq in mode=eval
INFO:tensorflow:
AttentionSeq2Seq:
  attention.class: seq2seq.decoders.attention.AttentionLayerBahdanau
  attention.params: {num_units: 256}
  bridge.class: seq2seq.models.bridges.ZeroBridge
  bridge.params: {}
  decoder.class: seq2seq.decoders.AttentionDecoder
  decoder.params:
    rnn_cell:
      cell_class: GRUCell
      cell_params: {num_units: 256}
      dropout_input_keep_prob: 0.8
      dropout_output_keep_prob: 1.0
      num_layers: 2
  embedding.dim: 256
  embedding.init_scale: 0.04
  embedding.share: false
  encoder.class: seq2seq.encoders.BidirectionalRNNEncoder
  encoder.params:
    rnn_cell:
      cell_class: GRUCell
      cell_params: {num_units: 256}
      dropout_input_keep_prob: 0.8
      dropout_output_keep_prob: 1.0
      num_layers: 1
  inference.beam_search.beam_width: 0
  inference.beam_search.choose_successors_fn: choose_top_k
  inference.beam_search.length_penalty_weight: 0.0
  optimizer.clip_embed_gradients: 0.1
  optimizer.clip_gradients: 5.0
  optimizer.learning_rate: 0.0001
  optimizer.lr_decay_rate: 0.99
  optimizer.lr_decay_steps: 100
  optimizer.lr_decay_type: ''
  optimizer.lr_min_learning_rate: 1.0e-12
  optimizer.lr_staircase: false
  optimizer.lr_start_decay_at: 0
  optimizer.lr_stop_decay_at: 2147483647
  optimizer.name: Adam
  optimizer.params: {epsilon: 8.0e-07}
  optimizer.sync_replicas: 0
  optimizer.sync_replicas_to_aggregate: 0
  source.max_seq_len: 50
  source.reverse: false
  target.max_seq_len: 50
  vocab_source: /home/scratch/sywang/project/dataset/google/50//train/vocab.buggy.txt
  vocab_target: /home/scratch/sywang/project/dataset/google/50//train/vocab.fixed.txt

INFO:tensorflow:Creating vocabulary lookup table of size 338
INFO:tensorflow:Creating vocabulary lookup table of size 334
INFO:tensorflow:Creating BidirectionalRNNEncoder in mode=eval
INFO:tensorflow:
BidirectionalRNNEncoder:
  init_scale: 0.04
  rnn_cell:
    cell_class: GRUCell
    cell_params: {num_units: 256}
    dropout_input_keep_prob: 0.8
    dropout_output_keep_prob: 1.0
    num_layers: 1
    residual_combiner: add
    residual_connections: false
    residual_dense: false

INFO:tensorflow:Creating AttentionLayerBahdanau in mode=eval
INFO:tensorflow:
AttentionLayerBahdanau: {num_units: 256}

INFO:tensorflow:Creating AttentionDecoder in mode=eval
INFO:tensorflow:
AttentionDecoder:
  init_scale: 0.04
  max_decode_length: 100
  rnn_cell:
    cell_class: GRUCell
    cell_params: {num_units: 256}
    dropout_input_keep_prob: 0.8
    dropout_output_keep_prob: 1.0
    num_layers: 2
    residual_combiner: add
    residual_connections: false
    residual_dense: false

INFO:tensorflow:Creating ZeroBridge in mode=eval
INFO:tensorflow:
ZeroBridge: {}

WARNING:tensorflow:From /home/scratch/sywang/seq2seq/seq2seq/metrics/metric_specs.py:232: streaming_mean (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.metrics.mean
INFO:tensorflow:Starting evaluation at 2018-09-26-18:46:27
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /home/scratch/sywang/project/dataset/google/50/model.ckpt-11000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Finished evaluation at 2018-09-26-18:46:29
INFO:tensorflow:Saving dict for global step 11000: bleu = 47.67, global_step = 11000, log_perplexity = 1.0999182, loss = 1.1002264
WARNING:tensorflow:Issue encountered when serializing variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'tokens_counter' has type str, but expected one of: int, long, bool
WARNING:tensorflow:Issue encountered when serializing trainable_variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'tokens_counter' has type str, but expected one of: int, long, bool
INFO:tensorflow:Stop training model as max steps reached
Parsing Inputs...
--------------- TRAINING ENDED ---------------------
------------------- TESTING GREEDY ------------------------
/home/scratch/sywang/anaconda3/lib/python3.5/site-packages/sklearn/utils/fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead
  if 'order' in inspect.getargspec(np.copy)[0]:
INFO:tensorflow:Creating ParallelTextInputPipeline in mode=infer
INFO:tensorflow:
ParallelTextInputPipeline:
  num_epochs: 1
  shuffle: false
  source_delimiter: ' '
  source_files: [/home/scratch/sywang/project/dataset/google/50//test/buggy.txt]
  target_delimiter: ' '
  target_files: []

INFO:tensorflow:Creating AttentionSeq2Seq in mode=infer
INFO:tensorflow:
AttentionSeq2Seq:
  attention.class: seq2seq.decoders.attention.AttentionLayerBahdanau
  attention.params: {num_units: 256}
  bridge.class: seq2seq.models.bridges.ZeroBridge
  bridge.params: {}
  decoder.class: seq2seq.decoders.AttentionDecoder
  decoder.params:
    rnn_cell:
      cell_class: GRUCell
      cell_params: {num_units: 256}
      dropout_input_keep_prob: 0.8
      dropout_output_keep_prob: 1.0
      num_layers: 2
  embedding.dim: 256
  embedding.init_scale: 0.04
  embedding.share: false
  encoder.class: seq2seq.encoders.BidirectionalRNNEncoder
  encoder.params:
    rnn_cell:
      cell_class: GRUCell
      cell_params: {num_units: 256}
      dropout_input_keep_prob: 0.8
      dropout_output_keep_prob: 1.0
      num_layers: 1
  inference.beam_search.beam_width: 0
  inference.beam_search.choose_successors_fn: choose_top_k
  inference.beam_search.length_penalty_weight: 0.0
  optimizer.clip_embed_gradients: 0.1
  optimizer.clip_gradients: 5.0
  optimizer.learning_rate: 0.0001
  optimizer.lr_decay_rate: 0.99
  optimizer.lr_decay_steps: 100
  optimizer.lr_decay_type: ''
  optimizer.lr_min_learning_rate: 1.0e-12
  optimizer.lr_staircase: false
  optimizer.lr_start_decay_at: 0
  optimizer.lr_stop_decay_at: 2147483647
  optimizer.name: Adam
  optimizer.params: {epsilon: 8.0e-07}
  optimizer.sync_replicas: 0
  optimizer.sync_replicas_to_aggregate: 0
  source.max_seq_len: 50
  source.reverse: false
  target.max_seq_len: 50
  vocab_source: /home/scratch/sywang/project/dataset/google/50//train/vocab.buggy.txt
  vocab_target: /home/scratch/sywang/project/dataset/google/50//train/vocab.fixed.txt

INFO:tensorflow:Creating DecodeText in mode=infer
INFO:tensorflow:
DecodeText: {delimiter: ' ', postproc_fn: '', unk_mapping: null, unk_replace: false}

INFO:tensorflow:Creating vocabulary lookup table of size 338
INFO:tensorflow:Creating vocabulary lookup table of size 334
INFO:tensorflow:Creating BidirectionalRNNEncoder in mode=infer
INFO:tensorflow:
BidirectionalRNNEncoder:
  init_scale: 0.04
  rnn_cell:
    cell_class: GRUCell
    cell_params: {num_units: 256}
    dropout_input_keep_prob: 0.8
    dropout_output_keep_prob: 1.0
    num_layers: 1
    residual_combiner: add
    residual_connections: false
    residual_dense: false

WARNING:tensorflow:From /home/scratch/sywang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.
Instructions for updating:
seq_dim is deprecated, use seq_axis instead
WARNING:tensorflow:From /home/scratch/sywang/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.
Instructions for updating:
batch_dim is deprecated, use batch_axis instead
INFO:tensorflow:Creating AttentionLayerBahdanau in mode=infer
INFO:tensorflow:
AttentionLayerBahdanau: {num_units: 256}

INFO:tensorflow:Creating AttentionDecoder in mode=infer
INFO:tensorflow:
AttentionDecoder:
  init_scale: 0.04
  max_decode_length: 100
  rnn_cell:
    cell_class: GRUCell
    cell_params: {num_units: 256}
    dropout_input_keep_prob: 0.8
    dropout_output_keep_prob: 1.0
    num_layers: 2
    residual_combiner: add
    residual_connections: false
    residual_dense: false

INFO:tensorflow:Creating ZeroBridge in mode=infer
INFO:tensorflow:
ZeroBridge: {}

WARNING:tensorflow:From /home/scratch/sywang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/function.py:986: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.
Instructions for updating:
Shapes are always computed; don't use the compute_shapes as it has no effect.
INFO:tensorflow:Graph was finalized.
2018-09-26 14:46:38.024533: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
INFO:tensorflow:Restoring parameters from /home/scratch/sywang/project/dataset/google/50/model.ckpt-11000
INFO:tensorflow:Restored model from /home/scratch/sywang/project/dataset/google/50/model.ckpt-11000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
------------------- TESTING BEAM SEARCH ------------------------
/home/scratch/sywang/anaconda3/lib/python3.5/site-packages/sklearn/utils/fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead
  if 'order' in inspect.getargspec(np.copy)[0]:
INFO:tensorflow:Creating ParallelTextInputPipeline in mode=infer
INFO:tensorflow:
ParallelTextInputPipeline:
  num_epochs: 1
  shuffle: false
  source_delimiter: ' '
  source_files: [/home/scratch/sywang/project/dataset/google/50//test/buggy.txt]
  target_delimiter: ' '
  target_files: []

INFO:tensorflow:Creating AttentionSeq2Seq in mode=infer
INFO:tensorflow:
AttentionSeq2Seq:
  attention.class: seq2seq.decoders.attention.AttentionLayerBahdanau
  attention.params: {num_units: 256}
  bridge.class: seq2seq.models.bridges.ZeroBridge
  bridge.params: {}
  decoder.class: seq2seq.decoders.AttentionDecoder
  decoder.params:
    rnn_cell:
      cell_class: GRUCell
      cell_params: {num_units: 256}
      dropout_input_keep_prob: 0.8
      dropout_output_keep_prob: 1.0
      num_layers: 2
  embedding.dim: 256
  embedding.init_scale: 0.04
  embedding.share: false
  encoder.class: seq2seq.encoders.BidirectionalRNNEncoder
  encoder.params:
    rnn_cell:
      cell_class: GRUCell
      cell_params: {num_units: 256}
      dropout_input_keep_prob: 0.8
      dropout_output_keep_prob: 1.0
      num_layers: 1
  inference.beam_search.beam_width: 5
  inference.beam_search.choose_successors_fn: choose_top_k
  inference.beam_search.length_penalty_weight: 0.0
  optimizer.clip_embed_gradients: 0.1
  optimizer.clip_gradients: 5.0
  optimizer.learning_rate: 0.0001
  optimizer.lr_decay_rate: 0.99
  optimizer.lr_decay_steps: 100
  optimizer.lr_decay_type: ''
  optimizer.lr_min_learning_rate: 1.0e-12
  optimizer.lr_staircase: false
  optimizer.lr_start_decay_at: 0
  optimizer.lr_stop_decay_at: 2147483647
  optimizer.name: Adam
  optimizer.params: {epsilon: 8.0e-07}
  optimizer.sync_replicas: 0
  optimizer.sync_replicas_to_aggregate: 0
  source.max_seq_len: 50
  source.reverse: false
  target.max_seq_len: 50
  vocab_source: /home/scratch/sywang/project/dataset/google/50//train/vocab.buggy.txt
  vocab_target: /home/scratch/sywang/project/dataset/google/50//train/vocab.fixed.txt

INFO:tensorflow:Creating DecodeText in mode=infer
INFO:tensorflow:
DecodeText: {delimiter: ' ', postproc_fn: '', unk_mapping: null, unk_replace: false}

INFO:tensorflow:Creating DumpBeams in mode=infer
INFO:tensorflow:
DumpBeams: {file: /home/scratch/sywang/project/dataset/google/50//pred/beams.npz}

INFO:tensorflow:Setting batch size to 1 for beam search.
INFO:tensorflow:Creating vocabulary lookup table of size 338
INFO:tensorflow:Creating vocabulary lookup table of size 334
INFO:tensorflow:Creating BidirectionalRNNEncoder in mode=infer
INFO:tensorflow:
BidirectionalRNNEncoder:
  init_scale: 0.04
  rnn_cell:
    cell_class: GRUCell
    cell_params: {num_units: 256}
    dropout_input_keep_prob: 0.8
    dropout_output_keep_prob: 1.0
    num_layers: 1
    residual_combiner: add
    residual_connections: false
    residual_dense: false

WARNING:tensorflow:From /home/scratch/sywang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.
Instructions for updating:
seq_dim is deprecated, use seq_axis instead
WARNING:tensorflow:From /home/scratch/sywang/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.
Instructions for updating:
batch_dim is deprecated, use batch_axis instead
INFO:tensorflow:Creating AttentionLayerBahdanau in mode=infer
INFO:tensorflow:
AttentionLayerBahdanau: {num_units: 256}

INFO:tensorflow:Creating AttentionDecoder in mode=infer
INFO:tensorflow:
AttentionDecoder:
  init_scale: 0.04
  max_decode_length: 100
  rnn_cell:
    cell_class: GRUCell
    cell_params: {num_units: 256}
    dropout_input_keep_prob: 0.8
    dropout_output_keep_prob: 1.0
    num_layers: 2
    residual_combiner: add
    residual_connections: false
    residual_dense: false

INFO:tensorflow:Creating BeamSearchDecoder in mode=infer
INFO:tensorflow:
BeamSearchDecoder:
  init_scale: 0.04
  max_decode_length: 100
  rnn_cell:
    cell_class: GRUCell
    cell_params: {num_units: 256}
    dropout_input_keep_prob: 1.0
    dropout_output_keep_prob: 1.0
    num_layers: 2
    residual_combiner: add
    residual_connections: false
    residual_dense: false

INFO:tensorflow:Creating ZeroBridge in mode=infer
INFO:tensorflow:
ZeroBridge: {}

WARNING:tensorflow:From /home/scratch/sywang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/function.py:986: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.
Instructions for updating:
Shapes are always computed; don't use the compute_shapes as it has no effect.
INFO:tensorflow:Graph was finalized.
2018-09-26 14:46:46.524640: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
INFO:tensorflow:Restoring parameters from /home/scratch/sywang/project/dataset/google/50/model.ckpt-11000
INFO:tensorflow:Restored model from /home/scratch/sywang/project/dataset/google/50/model.ckpt-11000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
------------------- BLEU ------------------------
buggy vs fixed
BLEU = 77.65, 85.1/80.5/75.4/70.4 (BP=1.000, ratio=1.088, hyp_len=6690, ref_len=6150)
prediction vs fixed
BLEU = 39.72, 74.1/52.3/36.3/25.0 (BP=0.917, ratio=0.920, hyp_len=5660, ref_len=6150)
prediction.beam vs fixed
BLEU = 37.89, 77.8/56.4/40.0/27.7 (BP=0.807, ratio=0.823, hyp_len=5063, ref_len=6150)
------------------- CLASSIFICATION ------------------------
Predictions
Perf: python3:
Pot : can't
Bad : open
Predictions.beam
Perf: python3:
Pot : can't
Bad : open
